---
title: "Assignment 2 Final Report"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
## clean memory
rm(list=ls()) 
```


```{r}
#Load data
library(fpp3) 
library(GGally) 
library(tseries)
library(forecast)
library(readxl)  
library(cowplot) 
library(rlist)    
library(svMisc)   
library(tseries)
library(dplyr)
library(lubridate)
library(zoo)
library(xts)
library(ggplot2)
library(dLagM)
library(lmtest)
library(vars)
```

```{r}
# Load raw Data
CPI_data <- suppressMessages(read_excel("640101.xlsx",sheet="Data1"))
GDP_data <- suppressMessages(read_excel("5206001_Key_Aggregates.xlsx",sheet="Data1"))
UM_data <- suppressMessages(read_excel("6202001.xlsx",sheet="Data1"))
CR_data <- suppressMessages(read_excel("f01hist.xls",sheet="Data"))
```
 
#Proposal part
#Data Transformation
```{r}
# Remove unnecessary rows and columns
dfCPI <- CPI_data %>% 
  select(...1,`Index Numbers ;  All groups CPI ;  Australia ;`) #Select the first column and add 'Index Numbers... Column -> Index Numbers ;  All groups CPI ;  Australia ;
dfCPI <- dfCPI[-c(1:9),] #Delete row 1 to 9

dfGDP <- GDP_data %>%
  select(...1,`GDP per capita: Current prices ;...99`) #The number behind is the column number where the original is 98 so we will plus 1 = 99
dfGDP <- dfGDP[-c(1:9),] 
 
dfUM <- UM_data %>%
  select(...1,`Unemployment rate ;  Persons ;...67`) #The number behind is the column number where the original is 66 so we will plus 1 = 67
dfUM <- dfUM[-c(1:9),] 
 
dfCR <- CR_data  %>%
  select('F1.1 INTEREST RATES AND YIELDS – MONEY MARKET',`...2`)
dfCR <- dfCR[-c(1:10),]
 
 
dfCR <- dfCR  %>%
  select('F1.1 INTEREST RATES AND YIELDS – MONEY MARKET',`...2`) #Get data from column 2 in the F1.1 Interest Rates
dfCR <- dfCR[-c(1:83),]
```

```{r}
# Rename Columns
colnames(dfCPI) = c("Dates","CPI")
colnames(dfGDP) = c("Dates","GDP")
colnames(dfUM) = c("Dates","unemployment_rate")
colnames(dfCR) = c("Dates","cash_rate")
```

```{r}
# Convert dates
# We will convert from normal number to date in the format of "1899-12-30"
dfCPI %<>%
  mutate_if(is.character,as.numeric) %>%
  mutate(Dates = as_date(Dates, origin = "1899-12-30"))
 
dfGDP %<>%
  mutate_if(is.character,as.numeric) %>%
  mutate(Dates = as_date(Dates, origin = "1899-12-30"))
 
dfUM <- dfUM %>% 
  mutate(Dates = as_date(as.numeric(Dates), origin = "1899-12-30"),
         unemployment_rate = as.numeric(unemployment_rate))
 
dfCR %<>%
  mutate_if(is.character,as.numeric) %>%
  mutate(Dates = as_date(Dates, origin = "1899-12-30"))
```
 
```{r}
# Cut Sample to 1992Q1-2023Q1
#Filter Date for targeting 1992
dfCPIshort <- dfCPI[which(dfCPI$Dates>="1991-03-01"),]
dfGDPshort <- dfGDP[which(dfGDP$Dates>="1991-03-01"),]
dfUMshort <- dfUM[which(dfUM$Dates>="1992-01-01"),]
dfCRshort <- dfCR[which(dfCR$Dates>="1992-01-01"),]
```

```{r}
# Transformations
dfCPIshort %>% mutate_if(is.character,as.numeric) %>%
mutate(Dates = as_date(Dates, origin = "1899-12-30")) %>% 
mutate(Inflation = 100*((CPI/lag(CPI,4))-1))   %>% 
na.omit(dfCPIshort)  %>% 
mutate(Dates = yearquarter(Dates))  %>% 
as_tsibble(index = Dates) -> dfCPIshort
 
dfGDPshort %>% mutate_if(is.character,as.numeric) %>%
mutate(Dates = as_date(Dates, origin = "1899-12-30")) %>% 
mutate(Growth = 100*((GDP/lag(GDP,4))-1))   %>% 
na.omit(dfGDPshort)  %>% 
mutate(Dates = yearquarter(Dates))  %>% 
as_tsibble(index = Dates) -> dfGDPshort
 
dfUMshort <- dfUMshort %>% mutate(year = year(Dates), quarter = quarters(Dates))
dfUMshort <- dfUMshort %>%
  group_by(year, quarter) %>%
  summarize(quarterly_average_unemployment_rate = round(mean(unemployment_rate),4))
dfUMshort <- dfUMshort %>%
  mutate(month = case_when(quarter == "Q1" ~ "03-01", 
                           quarter == "Q2" ~ "06-01", 
                           quarter == "Q3" ~ "09-01", 
                           quarter == "Q4" ~ "12-01"))
dfUMshort <- dfUMshort %>% mutate(Dates = paste0(year, '-', month))
dfUMshort$Dates <- as_date(dfUMshort$Dates)
dfUMshort <- dfUMshort[, c(5,3)]
dfUMshort <- dfUMshort %>%
  as_tsibble(index = Dates) %>%
  mutate(Dates = yearquarter(Dates))
dfUMshort <- dfUMshort[1:125,]

dfCRshort <- dfCRshort %>% mutate(year = year(Dates), quarter = quarters(Dates))
dfCRshort <- dfCRshort %>%
  group_by(year, quarter) %>%
  summarize(quarterly_average_cash_rate = round(mean(cash_rate),4))
dfCRshort <- dfCRshort %>%
  mutate(month = case_when(quarter == "Q1" ~ "03-01", 
                           quarter == "Q2" ~ "06-01", 
                           quarter == "Q3" ~ "09-01", 
                           quarter == "Q4" ~ "12-01"))
dfCRshort <- dfCRshort %>% mutate(Dates = paste0(year, '-', month))
dfCRshort$Dates <- as_date(dfCRshort$Dates)
dfCRshort <- dfCRshort[, c(5,3)]
dfCRshort <- dfCRshort %>%
  as_tsibble(index = Dates) %>%
  mutate(Dates = yearquarter(Dates))
dfCRshort <- dfCRshort[1:125,]
```

#Original plot without cutting to check votality of the data during the period before 1980Q1

Data confirm that there are high volatility before 1980Q1 for CPI Inflation and GDP Growth
```{r}
# Plot 
# Convert dates
dfCPI %<>% 
  mutate_if(is.character,as.numeric) %>%# Convert all numbers to numeric
  mutate(Dates = as_date(Dates, origin = "1899-12-30")) # Simplify dates to show only the year

dfGDP %<>%
  mutate_if(is.character,as.numeric) %>%
  mutate(Dates = as_date(Dates, origin = "1899-12-30"))

dfCR %<>%
  mutate_if(is.character,as.numeric) %>%
  mutate(Dates = as_date(Dates, origin = "1899-12-30"))

# Transformations
dfCPI %>% mutate_if(is.character,as.numeric) %>%
mutate(Dates = as_date(Dates, origin = "1899-12-30")) %>% 
mutate(Inflation = 100*((CPI/lag(CPI,4))-1))   %>% 
na.omit(dfCPI)  %>% 
mutate(Dates = yearquarter(Dates))  %>% 
as_tsibble(index = Dates) -> dfCPI

dfGDP %>% mutate_if(is.character,as.numeric) %>%
mutate(Dates = as_date(Dates, origin = "1899-12-30")) %>% 
mutate(Growth = 100*((GDP/lag(GDP,4))-1))   %>% 
na.omit(dfGDP)  %>% 
mutate(Dates = yearquarter(Dates))  %>% 
as_tsibble(index = Dates) -> dfGDP

# Plot 
ggplot(data = dfCPI, aes(x = Dates, y = Inflation)) +
    geom_line() +
    ggtitle("Australian CPI Inflation: 1951Q3-2023Q1")

ggplot(data = dfGDP, aes(x = Dates, y = Growth)) +
  geom_line() +
  ggtitle("Australian GDP growth: 1960Q3-2023Q1") +
  xlab("Dates") +
  ylab("GDP Growth %")
```

```{r}
# Plot 
ggplot(data = dfCPIshort, aes(x = Dates, y = Inflation)) +
  geom_line() +
  ggtitle("Australian CPI Inflation: 1992Q1-2023Q1") +
  xlab("Dates") +
  ylab("CPI Inflationn %")

ggplot(data = dfGDPshort, aes(x = Dates, y = Growth)) +
  geom_line() +
  ggtitle("Australian GDP growth: 1992Q1-2023Q1") +
  xlab("Dates") +
  ylab("GDP Growth %")

ggplot(data = dfUMshort, aes(x = Dates, y = quarterly_average_unemployment_rate)) +
  geom_line() +
  ggtitle("Australian Quarterly Average Unemployment Rate: 1992Q1-2023Q1") +
  xlab("Dates") +
  ylab("Unemployment Rate %")

ggplot(data = dfCRshort, aes(x = Dates, y = quarterly_average_cash_rate)) +
  geom_line() +
  ggtitle("Australian Quarterly Average Cash Rate: 1992Q1-2023Q1") +
  xlab("Dates") +
  ylab("Cash Rate %")

ggplot() +
  geom_line(data = dfCPIshort, aes(x = Dates, y = Inflation), color = "red") +
  geom_line(data = dfGDPshort, aes(x = Dates, y = Growth), color = "blue") +
  geom_line(data = dfUMshort, aes(x = Dates, y = quarterly_average_unemployment_rate), color = "purple") +
  geom_line(data = dfCRshort, aes(x = Dates, y = quarterly_average_cash_rate), color = "orange") +
  geom_text(data = dfCPIshort, aes(x = max(Dates), y = max(Inflation), label = "Inflation"), vjust = -0.5, color = "red") +
  geom_text(data = dfGDPshort, aes(x = max(Dates), y = max(Growth), label = "GDP Growth"), vjust = -0.5, color = "blue") +
  geom_text(data = dfUMshort, aes(x = max(Dates), y = max(quarterly_average_unemployment_rate), label = "Unemployment"), vjust = -0.5, color = "purple") +
  geom_text(data = dfCRshort, aes(x = max(Dates), y = max(quarterly_average_cash_rate), label = "Cash Rate"), vjust = -0.5, color = "orange") +
  ggtitle("Australian Economic Indicators: 1992Q1-2023Q1") +
  xlab("Dates") +
  ylab("Percentage %")
```
# Correlograms

#ACF of CPI and GDP Growth
```{r}
# Plot ACF
plot_1 <-
  dfCPIshort |>
  ACF(Inflation) |>
  autoplot() + 
  labs(title="ACF of CPI Inflation")

plot_2 <-
  dfGDPshort |>
  ACF(Growth) |>
  autoplot() + 
  labs(title="ACF of GDP Growth")

plot_grid(plot_1, plot_2, ncol = 1)
```

#ACF of Unemployment Rate and Cash Rate
```{r}
# Convert dfUMshort to a tsibble
dfUMshort$Dates <- as_date(dfUMshort$Dates)
dfCRshort$Dates <- as_date(dfCRshort$Dates)

dfUMshort <- dfUMshort %>%
  as_tsibble(index = Dates) %>%
  mutate(Dates = yearquarter(Dates))

dfCRshort <- dfCRshort %>%
  as_tsibble(index = Dates) %>%
  mutate(Dates = yearquarter(Dates))

# Plot ACF
plot_3 <-
dfUMshort |>
  ACF(quarterly_average_unemployment_rate) |>
  autoplot() +
  labs(title = "ACF of Unemployment Rate")

plot_4 <-
dfCRshort |>
  ACF(quarterly_average_cash_rate) |>
  autoplot() +
  labs(title = "ACF of Cash Rate")
plot_grid(plot_3,  plot_4, ncol = 1)
```

#PACF of CPI and GDP Growth
```{r}
plot_5 <-
  dfCPIshort |>
  PACF(Inflation) |>
  autoplot() + 
  labs(title="PACF of CPI Inflation")

plot_6 <-
  dfGDPshort |>
  PACF(Growth) |>
  autoplot() + 
  labs(title="PACF of GDP Growth")

plot_grid(plot_5, plot_6, ncol = 1)
```

#PACF of Unemployment Rate and Cash Rate
```{r}
plot_7 <-
  dfUMshort |>
  PACF(quarterly_average_unemployment_rate) |>
  autoplot() + 
  labs(title="PACF of Unemployment Rate")

plot_8 <-
  dfCRshort |>
  PACF(quarterly_average_cash_rate) |>
  autoplot() + 
  labs(title="PACF of Cash Rate")

plot_grid(plot_7, plot_8, ncol = 1)
```

```{r}
# combine all data into a dataset
combined_data <- data.frame(Dates = dfCPIshort$Dates, CPI_Inflation = dfCPIshort$Inflation, GDP_Growth_Rate = dfGDPshort$Growth, Average_Unemployment_Rate = dfUMshort$quarterly_average_unemployment_rate, Average_Cash_Rate=dfCRshort$quarterly_average_cash_rate)
combined_data
```
 
```{r}
# Redefine inflation as .ts object to use various forecasting packages
dfCPI_new = ts(dfCPIshort[,3],
            start=c(1992, 1), 
            end=c(2023, 1), 
            frequency=4)

dfGDP_new = ts(dfGDPshort[,3],
           start=c(1992, 1), 
           end=c(2023, 1), 
           frequency=4)

dfUM_new = ts(dfUMshort[,2],
           start=c(1992, 1), 
           end=c(2023, 1), 
           frequency=4)

dfCR_new = ts(dfCRshort[,2],
              start=c(1992, 1), 
              end=c(2023, 1), 
              frequency=4)
```

#Final Report part

#Perform ADF and KPSS Test
```{r}
# Test
# These data need to convert to univariate time series
# ADF -> signifiacnt suggests stationary
adf.test(dfCPI_new,alternative = "stationary") #non-stationary
adf.test(dfGDP_new,alternative = "stationary") #non-stationary
adf.test(dfUM_new,alternative = "stationary") #stationary

# KPSS -> insignificant suggests stationary
kpss.test(dfCPI_new) #stationary
kpss.test(dfGDP_new) #stationary
kpss.test(dfUM_new) #non-stationary

#We have conflict results here,so we will need to do first differencing
```

CPI Inflation

The series does not look stationary because the mean seems not constant overtime. We can also check more formally by running statistical tests such as the ADF and KPSS tests. 

The test results show that:

1. ADF test: p-value = 0.4837. This means that we fail to reject the null of a unit root. We conclude that there is insufficient evidence to conclude that the series is stationary.
2. KPSS test: p-value = 0.1. This means that we fail to reject the null of stationarity. This suggests that the series is stationary.

Taken together there is conflict result, since the data have been done with the annualized differencing (seasonal differenced), therefore the differencing approach is not required. We will give it for the future reseach.

GDP Growth

The series does not look stationary because the mean seems not constant overtime. We can also check more formally by running statistical tests such as the ADF and KPSS tests. 

The test results show that:

1. ADF test: p-value = 0.3408. This means that we fail to reject the null of a unit root. We conclude that there is insufficient evidence to conclude that the series is stationary.
2. KPSS test: p-value = 0.1. This means that we fail to reject the null of stationarity. This suggests that the series is stationary.

Taken together there is conflict result, since the data have been done with the annualized differencing (seasonal differenced), therefore the differencing approach is not required. We will give it for the future reseach.

Unemployment Rate

The series does not look stationary because the mean seems not constant overtime and it has a trend (time-dependent mean) during 1992 to 2008. We can also check more formally by running statistical tests such as the ADF and KPSS tests. 

The test results show that:

1. ADF test: p-value = 0.03218. This means that we reject the null of a unit root. We conclude that there is sufficient evidence to conclude that the series is stationary.
2. KPSS test: p-value = 0.01. This means that we reject the null of stationarity. This suggests that the series is not stationary.

Taken together there is conflict result, therefore the first differencing approach is required then we can performa test again.

Cash Rate

The series does not look stationary because the mean seems not constant overtime and it has a trend (time-dependent mean) during 1992 to 2008. We can also check more formally by running statistical tests such as the ADF and KPSS tests. 

The test results show that:

1. ADF test: p-value = 0.1676. This means that we fail to reject the null of a unit root. We conclude that there is insufficient evidence to conclude that the series is stationary.
2. KPSS test: p-value = 0.01. This means that we reject the null of stationarity. This suggests that the series is not stationary.

Taken together there is ample evidence to suggest that the series is not stationary.

#How can we make the series stationary? Apply your ideas to make the series stationary.

```{r}
# Do first differencing
dfUM_new_diff = diff(dfUM_new)

# Plot to check the stationarity pattern
plot(dfCPI_new, xlab="Year", ylab="Inflation Rate %", main="CPI Inflation Rate")
plot(dfGDP_new, xlab="Year", ylab="GDP Growth Rate %", main="GDP Growth Rate")
plot(dfUM_new_diff, xlab="Year", ylab="Average Unemployment Rate %", main="Unemployment First-Differenced")

adf.test(dfUM_new_diff,alternative = "stationary") #stationary
kpss.test(dfUM_new_diff) #stationary
```

As the result from the fist differencing, we have adf and KPSS test conform each other in Unemployment. Taken together the evidence suggests that the resulting both series are stationary after the first-differencing. 

```{r}
## Split Sample
# Training set: 1978Q1--2007Q4
dfCPI_train=window(dfCPI_new,end=c(2011,4))
dfGDP_train=window(dfGDP_new,end=c(2011,4))
dfUM_train=window(dfUM_new,end=c(2011,4))
dfCR_train=window(dfCR_new,end=c(2011,4))
 
# Test set: 2008Q1--2023Q1
dfCPI_test=window(dfCPI_new,start=c(2012,1))
dfGDP_test=window(dfGDP_new,start=c(2012,1))
dfUM_test=window(dfUM_new,start=c(2012,1))
dfCR_test=window(dfCR_new,start=c(2012,1))
```

##Univariate MODEL

#Random Walk Model

```{r}
#Use RW without drift as the benchmark
fit_rwnd1 <- rwf(dfCPI_train)
summary(fit_rwnd1) #0.7984885
fit_rwnd2 <- rwf(dfGDP_train)
summary(fit_rwnd2) #1.43093
fit_rwnd3 <- rwf(dfUM_train)
summary(fit_rwnd3) #0.5834318
```

#auto ETS

```{r}
fit_ets_auto1 <- ets(dfCPI_train)
summary(fit_ets_auto1) #ETS(A,N,N) -> SES, 0.7934965
fit_ets_auto2 <- ets(dfGDP_train)
summary(fit_ets_auto2) #ETS(A,N,N) -> SES, 1.42198
fit_ets_auto3 <- ets(dfUM_train)
summary(fit_ets_auto3) #ETS(A,A,A) -> Holt-Winters with additive error, 0.246693
#fit_ets_auto4 <- ets(dfCR_train) 
#summary(fit_ets_auto4) #ETS(A,A,N) -> Holt's linear trend with additive error, 0.3893839
```

#AR Model using ARIMA function
#Initial guess from PACF plot(propose model) and first differenced
```{r}
#AR Model using ARIMA function

#Inflation
fit_AR1 <- Arima(dfCPI_train,c(9,0,0))
summary(fit_AR1) # 0.6235033

#GDP Growth
fit_AR2 <- Arima(dfGDP_train,c(6,0,0))
summary(fit_AR2) # 1.054646

#Unemployment
fit_AR3 <- Arima(dfUM_train,c(14,1,0)) #Best model for UM Rate, which better than auto Arima
summary(fit_AR3) # 0.2151863

#Cash Rate
#fit_AR4 <- Arima(dfCR_train,c(9,1,0))
#summary(fit_AR4) # 0.3184467
```

#Auto ARIMA
```{r}
# Automatically fit an ARIMA model on the training data
fit_ARIMA_auto1<-auto.arima(dfCPI_train, seasonal=FALSE) #We will not look at seasonal effect
summary(fit_ARIMA_auto1) #ARIMA(2,0,2), 0.6689577 -> This is ARMA model

fit_ARIMA_auto2<-auto.arima(dfGDP_train, seasonal=FALSE) 
summary(fit_ARIMA_auto2) #ARIMA(0,0,3), 1.061051 -> This is moving average model

fit_ARIMA_auto3<-auto.arima(dfUM_train, seasonal=FALSE) 
summary(fit_ARIMA_auto3) #ARIMA(0,1,1) with drift, 0.5290688 -> This is moving average model with first-differenced
```

#Summary of the Training Set

CPI Inflation, ARIMA(9,0,0) (AR Model with lag(9)) perform the best.
GDP Growth, ARIMA(6,0,0) (AR Model with lag(6)) perform the best.
UM Rate, ARIMA(14,1,0) (AR Model with lag(14)) perform the best.

#Perform four step ahead forecast with loop

#Inflation Rate
```{r}
# Define useful inputs
T <- nrow(dfCPI_new)  # Number of time periods in data set
T0 <- nrow(dfCPI_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd1.4 = list()
sfcast_ETS1.4 = list()
sfcast_AR1.4 = list() #We will use this to store three series, which are actual, forecast, error
sfcast_ARIMA_auto1.4 = list()


# Loop
for (tt in 1:(nfcasts-4)) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train1.4 = ts(dfCPI_new[1:(T0+tt-1),]) 

  # Fit the models
  fit_ETS1.4 <- ets(y_train1.4) # Automatic selection of ets - may change over test sample
  fit_AR1.4 <- Arima(y_train1.4,c(9,0,0))
  fit_ARIMA_auto1.4 <- auto.arima(y_train1.4, seasonal=FALSE) # Automatic selection of ARIMA 
  
  
  
# four-step-ahead forecast 
  fcast_rwnd1.4 <- rwf(y_train1.4,h=4)
  fcast_ETS1.4 <- forecast::forecast(fit_ETS1.4,h=4)
  fcast_AR1.4 <- forecast::forecast(fit_AR1.4,h=4)
  fcast_ARIMA_auto1.4 <- forecast::forecast(fit_ARIMA_auto1.4,h=4)
  
  

# Collect objects of interest 
  yobs1.4 <- (dfCPI_new[T0+tt]) # Value we want to forecast
  
  yhat_rwnd1.4 <- fcast_rwnd1.4$mean[1]
  yhat_ETS1.4 <- fcast_ETS1.4$mean[1] 
  yhat_AR1.4 <- fcast_AR1.4$mean[1] # Point forecast
  yhat_ARIMA_auto1.4 <- fcast_ARIMA_auto1.4$mean[1]


  err_rwnd1.4 <- yhat_rwnd1.4 - yobs1.4
  err_ETS1.4 <- yhat_ETS1.4 - yobs1.4
  err_AR1.4 <- yhat_AR1.4 - yobs1.4 # Forecast error
  err_ARIMA_auto1.4 <- yhat_ARIMA_auto1.4 - yobs1.4
  
  
# Store point forecast
  sfcast_rwnd1.4[[tt]] = c(yobs1.4,yhat_rwnd1.4,err_rwnd1.4)
  sfcast_ETS1.4[[tt]] = c(yobs1.4,yhat_ETS1.4,err_ETS1.4)
  sfcast_AR1.4[[tt]] = c(yobs1.4,yhat_AR1.4,err_AR1.4)
  sfcast_ARIMA_auto1.4[[tt]] = c(yobs1.4,yhat_ARIMA_auto1.4,err_ARIMA_auto1.4)
  
}

# Transform list to matrix
sfcast_rwnd1.4 = ts(list.rbind(sfcast_rwnd1.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ETS1.4 = ts(list.rbind(sfcast_ETS1.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_AR1.4 = ts(list.rbind(sfcast_AR1.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ARIMA_auto1.4 = ts(list.rbind(sfcast_ARIMA_auto1.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_rwnd1.4 = sqrt(mean((sfcast_rwnd1.4[,3])^2))
RMSE_ETS1.4 <- sqrt(mean((sfcast_ETS1.4[,3])^2))
RMSE_AR1.4 <- sqrt(mean((sfcast_AR1.4[,3])^2))
RMSE_ARIMA_auto1.4 <- sqrt(mean((sfcast_ARIMA_auto1.4[,3])^2))

RMSE1.4 <- c(RMSE_rwnd1.4, 
            RMSE_ETS1.4,
          RMSE_AR1.4,
          RMSE_ARIMA_auto1.4)

#Present Results
RMSE1.4 #As the result RW with no drift is perform the best.

# DM Test with RWnd Benchmark - one tailed
dm.test(sfcast_rwnd1.4[,3],sfcast_ETS1.4[,3],power=2, alternative='g')
dm.test(sfcast_rwnd1.4[,3],sfcast_AR1.4[,3],power=2, alternative='g')
dm.test(sfcast_rwnd1.4[,3],sfcast_ARIMA_auto1.4[,3],power=2, alternative='g')


# Plot
plot(dfCPI_test, 
     type ='l', 
     main="CPI Inflation Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_rwnd1.4[,2],col="red",type="l", lty=2)
lines(sfcast_ETS1.4[,2],col="blue",type='l', lty=4)
lines(sfcast_AR1.4[,2],col="purple",type="l", lty=5)
lines(sfcast_ARIMA_auto1.4[,2],col="green",type="l", lty=4)
legend("topleft", legend = c("Data", "RWnd", "ets", "ARIMA(9,0,0)", "ARIMA(2,0,2)"),
       col = c("black","red", "blue",'purple',"green"), lty = 1:5, cex = 0.8)

# Transform list to matrix
sfcast_rwnd1.4 = list.rbind(sfcast_rwnd1.4)
sfcast_ETS1.4 = list.rbind(sfcast_ETS1.4)
sfcast_AR1.4 = list.rbind(sfcast_AR1.4)
sfcast_ARIMA_auto1.4 = list.rbind(sfcast_ARIMA_auto1.4)

# Collect the results for print out
results <- ts(cbind(dfCPI_test,sfcast_rwnd1.4[2,],sfcast_ETS1.4[2,],sfcast_AR1.4[2,],sfcast_ARIMA_auto1.4[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","RWnd","ETS","ARIMA(9,0,0)","ARIMA(2,0,2)")

print(results)

```
We will use RW with no drift to be the benchmark. As the result ARIMA(9,0,0) is perform the best for four step ahead forecast and the line also conform with the original data. We will use DM test to compare. From DM test, it did not confirm that ARIMA(9,0,0) perform the better than RW statistically significant (This suggests that two models statistically equivalent accuracy) (for one step ahead forecast). However, ARIMA(9,0,0) has improved prediction performance by 16.5% (economic significant)

From the plotting, it also confirm that ARIMA(9,0,0) with four step ahead forecast has the plotting line close to the testing set (raw data) except 2021 Q3 onwards. This difference probably come from covid 19 Pandemic recovery and the number of step ahead for forecasting period.

#GDP Growth Rate
```{r}
# Define useful inputs
T <- nrow(dfGDP_new)  # Number of time periods in data set
T0 <- nrow(dfGDP_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd2.4 = list()
sfcast_ETS2.4 = list()
sfcast_AR2.4 = list() #We will use this to store three series, which are actual, forecast, error
sfcast_ARIMA_auto2.4 = list()


# Loop
for (tt in 1:(nfcasts-4)) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train2.4 = ts(dfGDP_new[1:(T0+tt-1),]) 

  # Fit the models
  fit_ETS2.4 <- ets(y_train2.4) # Automatic selection of ets - may change over test sample
  fit_AR2.4 <- Arima(y_train2.4,c(6,0,0))
  fit_ARIMA_auto2.4 <- auto.arima(y_train2.4, seasonal=FALSE) # Automatic selection of ARIMA 
  
  
  
# Four-step-ahead forecast 
  fcast_rwnd2.4 <- rwf(y_train2.4,h=4)
  fcast_ETS2.4 <- forecast::forecast(fit_ETS2.4,h=4)
  fcast_AR2.4 <- forecast::forecast(fit_AR2.4,h=4)
  fcast_ARIMA_auto2.4 <- forecast::forecast(fit_ARIMA_auto2.4,h=4)
  
  

# Collect objects of interest 
  yobs2.4 <- (dfGDP_new[T0+tt]) # Value we want to forecast
  
  yhat_rwnd2.4 <- fcast_rwnd2.4$mean[1]
  yhat_ETS2.4 <- fcast_ETS2.4$mean[1] 
  yhat_AR2.4 <- fcast_AR2.4$mean[1] # Point forecast
  yhat_ARIMA_auto2.4 <- fcast_ARIMA_auto2.4$mean[1]


  err_rwnd2.4 <- yhat_rwnd2.4 - yobs2.4
  err_ETS2.4 <- yhat_ETS2.4 - yobs2.4
  err_AR2.4 <- yhat_AR2.4 - yobs2.4 # Forecast error
  err_ARIMA_auto2.4 <- yhat_ARIMA_auto2.4 - yobs2.4
  
  
# Store point forecast
  sfcast_rwnd2.4[[tt]] = c(yobs2.4,yhat_rwnd2.4,err_rwnd2.4)
  sfcast_ETS2.4[[tt]] = c(yobs2.4,yhat_ETS2.4,err_ETS2.4)
  sfcast_AR2.4[[tt]] = c(yobs2.4,yhat_AR2.4,err_AR2.4)
  sfcast_ARIMA_auto2.4[[tt]] = c(yobs2.4,yhat_ARIMA_auto2.4,err_ARIMA_auto2.4)
  
}

# Transform list to matrix
sfcast_rwnd2.4 = ts(list.rbind(sfcast_rwnd2.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ETS2.4 = ts(list.rbind(sfcast_ETS2.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_AR2.4 = ts(list.rbind(sfcast_AR2.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ARIMA_auto2.4 = ts(list.rbind(sfcast_ARIMA_auto2.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_rwnd2.4 = sqrt(mean((sfcast_rwnd2.4[,3])^2)) #Use third column because it is for the storage of error data
RMSE_ETS2.4 <- sqrt(mean((sfcast_ETS2.4[,3])^2))
RMSE_AR2.4 <- sqrt(mean((sfcast_AR2.4[,3])^2))
RMSE_ARIMA_auto2.4 <- sqrt(mean((sfcast_ARIMA_auto2.4[,3])^2))

RMSE2.4 <- c(RMSE_rwnd2.4, 
            RMSE_ETS2.4,
          RMSE_AR2.4,
          RMSE_ARIMA_auto2.4)

#Present Results
RMSE2.4 #As the result RW with no drift is perform the best.

# DM Test with RWnd Benchmark - one tailed
dm.test(sfcast_rwnd2.4[,3],sfcast_ETS2.4[,3],power=2, alternative='g')
dm.test(sfcast_rwnd2.4[,3],sfcast_AR2.4[,3],power=2, alternative='g')
dm.test(sfcast_rwnd2.4[,3],sfcast_ARIMA_auto2.4[,3],power=2, alternative='g')


# Plot
plot(dfGDP_test, 
     type ='l', 
     main="GDP Growth Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_rwnd2.4[,2],col="red",type="l", lty=2)
lines(sfcast_ETS2.4[,2],col="blue",type='l', lty=4)
lines(sfcast_AR2.4[,2],col="purple",type="l", lty=5)
lines(sfcast_ARIMA_auto2.4[,2],col="green",type="l", lty=4)
legend("topleft", legend = c("Data", "RWnd", "ets", "ARIMA(6,0,0)", "ARIMA(3,0,2)"),
       col = c("black","red", "blue",'purple',"green"), lty = 1:5, cex = 0.8)

# Transform list to matrix
sfcast_rwnd2.4 = list.rbind(sfcast_rwnd2.4)
sfcast_ETS2.4 = list.rbind(sfcast_ETS2.4)
sfcast_AR2.4 = list.rbind(sfcast_AR2.4)
sfcast_ARIMA_auto2.4 = list.rbind(sfcast_ARIMA_auto2.4)

# Collect the results for print out
results <- ts(cbind(dfGDP_test,sfcast_rwnd2.4[2,],sfcast_ETS2.4[2,],sfcast_AR2.4[2,],sfcast_ARIMA_auto2.4[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","RWnd","ETS","ARIMA(6,0,0)","ARIMA(3,0,2)")

print(results)

```
We will use RW with no drift to be the benchmark. As the result ARIMA(6,0,0) is perform the best for four step ahead forecast and the line also conform with the original data. We will use DM test to compare. From DM test, it did not confirm that ARIMA(6,0,0) perform the better than RW statistically significant (for four step ahead forecast). However, ARIMA(6,0,0) is improve prediction performance (comparing from RMSE) by 15.7% (economic significant)

From the plotting, it also confirm that ARIMA(6,0,0) with one step ahead forecast has the plotting line close to the testing set (raw data) except 2021 Q3 onwards. This difference probably come from covid 19 Pandemic recovery and the number of step ahead for forecasting period.

#Unemployment Rate
```{r}
# Define useful inputs
T <- nrow(dfUM_new)  # Number of time periods in data set
T0 <- nrow(dfUM_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd3.4 = list()
sfcast_ETS3.4 = list()
sfcast_AR3.4 = list() #We will use this to store three series, which are actual, forecast, error
sfcast_ARIMA_auto3.4 = list()


# Loop
for (tt in 1:(nfcasts-4)) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train3.4 = ts(dfUM_new[1:(T0+tt-1),]) 

  # Fit the models
  fit_ETS3.4 <- ets(y_train3.4) # Automatic selection of ets - may change over test sample
  fit_AR3.4 <- Arima(y_train3.4,c(14,1,0))
  fit_ARIMA_auto3.4 <- auto.arima(y_train3.4, seasonal=FALSE) # Automatic selection of ARIMA 
  
  
  
# Four-step-ahead forecast 
  fcast_rwnd3.4 <- rwf(y_train3.4,h=4)
  fcast_ETS3.4 <- forecast::forecast(fit_ETS3.4,h=4)
  fcast_AR3.4 <- forecast::forecast(fit_AR3.4,h=4)
  fcast_ARIMA_auto3.4 <- forecast::forecast(fit_ARIMA_auto3.4,h=4)
  
  

# Collect objects of interest 
  yobs3.4 <- (dfUM_new[T0+tt]) # Value we want to forecast
  
  yhat_rwnd3.4 <- fcast_rwnd3.4$mean[1]
  yhat_ETS3.4 <- fcast_ETS3.4$mean[1] 
  yhat_AR3.4 <- fcast_AR3.4$mean[1] # Point forecast
  yhat_ARIMA_auto3.4 <- fcast_ARIMA_auto3.4$mean[1]


  err_rwnd3.4 <- yhat_rwnd3.4 - yobs3.4
  err_ETS3.4 <- yhat_ETS3.4 - yobs3.4
  err_AR3.4 <- yhat_AR3.4 - yobs3.4 # Forecast error
  err_ARIMA_auto3.4 <- yhat_ARIMA_auto3.4 - yobs3.4
  
  
# Store point forecast
  sfcast_rwnd3.4[[tt]] = c(yobs3.4,yhat_rwnd3.4,err_rwnd3.4)
  sfcast_ETS3.4[[tt]] = c(yobs3.4,yhat_ETS3.4,err_ETS3.4)
  sfcast_AR3.4[[tt]] = c(yobs3.4,yhat_AR3.4,err_AR3.4)
  sfcast_ARIMA_auto3.4[[tt]] = c(yobs3.4,yhat_ARIMA_auto3.4,err_ARIMA_auto3.4)
  
}

# Transform list to matrix
sfcast_rwnd3.4 = ts(list.rbind(sfcast_rwnd3.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ETS3.4 = ts(list.rbind(sfcast_ETS3.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_AR3.4 = ts(list.rbind(sfcast_AR3.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ARIMA_auto3.4 = ts(list.rbind(sfcast_ARIMA_auto3.4),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_rwnd3.4 = sqrt(mean((sfcast_rwnd3.4[,3])^2))
RMSE_ETS3.4 <- sqrt(mean((sfcast_ETS3.4[,3])^2))
RMSE_AR3.4 <- sqrt(mean((sfcast_AR3.4[,3])^2))
RMSE_ARIMA_auto3.4 <- sqrt(mean((sfcast_ARIMA_auto3.4[,3])^2))

RMSE3.4 <- c(RMSE_rwnd3.4, 
            RMSE_ETS3.4,
          RMSE_AR3.4,
          RMSE_ARIMA_auto3.4)

#Present Results
RMSE3.4 #As the result RW with no drift is perform the best.

# DM Test with RWnd Benchmark - one tailed
dm.test(sfcast_rwnd3.4[,3],sfcast_ETS3.4[,3],power=2, alternative='g')
dm.test(sfcast_rwnd3.4[,3],sfcast_AR3.4[,3],power=2, alternative='g')
dm.test(sfcast_rwnd3.4[,3],sfcast_ARIMA_auto3.4[,3],power=2, alternative='g')


# Plot
plot(dfUM_test, 
     type ='l', 
     main="Unemployment Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_rwnd3.4[,2],col="red",type="l", lty=2)
lines(sfcast_ETS3.4[,2],col="blue",type='l', lty=4)
lines(sfcast_AR3.4[,2],col="purple",type="l", lty=5)
lines(sfcast_ARIMA_auto3.4[,2],col="green",type="l", lty=4)
legend("bottomleft", legend = c("Data", "RWnd", "ets", "ARIMA(14,1,0)", "ARIMA(0,1,1)"),
       col = c("black","red", "blue",'purple',"green"), lty = 1:5, cex = 0.8)

# Transform list to matrix
sfcast_rwnd3.4 = list.rbind(sfcast_rwnd3.4)
sfcast_ETS3.4 = list.rbind(sfcast_ETS3.4)
sfcast_AR3.4 = list.rbind(sfcast_AR3.4)
sfcast_ARIMA_auto3.4 = list.rbind(sfcast_ARIMA_auto3.4)

# Collect the results for print out
results <- ts(cbind(dfUM_test,sfcast_rwnd3.4[2,],sfcast_ETS3.4[2,],sfcast_AR3.4[2,],sfcast_ARIMA_auto3.4[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","RWnd","ETS","ARIMA(14,1,0)","ARIMA(0,1,1)")

print(results)

```
We will use RW with no drift to be the benchmark. As the result ARIMA(14,1,0) is perform the best for one step ahead forecast and the line also conform with the original data. We will use DM test to compare. From DM test, it confirm that ARIMA(14,1,0) perform the better than RW statistically significant (for four step ahead forecast). It is improve prediction performance (comparing from RMSE) by 23% (economic significant)

From the plotting, it also confirm that ARIMA(14,1,0) with one step ahead forecast has the plotting line close to the testing set (raw data) except 2021 Q3 onwards. This difference probably come from covid 19 Pandemic recovery and the number of step ahead for forecasting period.

#Summary of the Testing Set with 4 step ahead forecast

CPI Inflation, ARIMA(9,0,0) perform the best.
GDP Growth, ARIMA(6,0,0) or AR(6) perform the best.
UM Rate, ARIMA(14,1,0) perform the best.

#Perform one step ahead forecast

#Inflation Rate
```{r}
# Define useful inputs
T <- nrow(dfCPI_new)  # Number of time periods in data set
T0 <- nrow(dfCPI_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd1 = list()
sfcast_ETS1 = list()
sfcast_AR1 = list() #We will use this to store three series, which are actual, forecast, error
sfcast_ARIMA_auto1 = list()


# Loop
for (tt in 1:nfcasts) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train = ts(dfCPI_new[1:(T0+tt-1),]) 

  # Fit the models
  fit_ETS1 <- ets(y_train) # Automatic selection of ets - may change over test sample
  fit_AR1 <- Arima(y_train,c(9,0,0))
  fit_ARIMA_auto1 <- auto.arima(y_train, seasonal=FALSE) # Automatic selection of ARIMA 
  
  
  
# One-step-ahead forecast 
  fcast_rwnd1 <- rwf(y_train,h=1)
  fcast_ETS1 <- forecast::forecast(fit_ETS1,h=1)
  fcast_AR1 <- forecast::forecast(fit_AR1,h=1)
  fcast_ARIMA_auto1 <- forecast::forecast(fit_ARIMA_auto1,h=1)
  
  

# Collect objects of interest 
  yobs <- (dfCPI_new[T0+tt]) # Value we want to forecast
  
  yhat_rwnd1 <- fcast_rwnd1$mean[1]
  yhat_ETS1 <- fcast_ETS1$mean[1] 
  yhat_AR1 <- fcast_AR1$mean[1] # Point forecast
  yhat_ARIMA_auto1 <- fcast_ARIMA_auto1$mean[1]


  err_rwnd1 <- yhat_rwnd1 - yobs
  err_ETS1 <- yhat_ETS1 - yobs
  err_AR1 <- yhat_AR1 - yobs # Forecast error
  err_ARIMA_auto1 <- yhat_ARIMA_auto1 - yobs
  
  
# Store point forecast
  sfcast_rwnd1[[tt]] = c(yobs,yhat_rwnd1,err_rwnd1)
  sfcast_ETS1[[tt]] = c(yobs,yhat_ETS1,err_ETS1)
  sfcast_AR1[[tt]] = c(yobs,yhat_AR1,err_AR1)
  sfcast_ARIMA_auto1[[tt]] = c(yobs,yhat_ARIMA_auto1,err_ARIMA_auto1)
  
}

# Transform list to matrix
sfcast_rwnd1 = ts(list.rbind(sfcast_rwnd1),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ETS1 = ts(list.rbind(sfcast_ETS1),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_AR1 = ts(list.rbind(sfcast_AR1),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ARIMA_auto1 = ts(list.rbind(sfcast_ARIMA_auto1),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_rwnd1 = sqrt(mean((sfcast_rwnd1[,3])^2))
RMSE_ETS1 <- sqrt(mean((sfcast_ETS1[,3])^2))
RMSE_AR1 <- sqrt(mean((sfcast_AR1[,3])^2))
RMSE_ARIMA_auto1 <- sqrt(mean((sfcast_ARIMA_auto1[,3])^2))

RMSE <- c(RMSE_rwnd1, 
            RMSE_ETS1,
          RMSE_AR1,
          RMSE_ARIMA_auto1)

#Present Results
RMSE #As the result RW with no drift is perform the best.

# DM Test with RWnd Benchmark - one tailed
dm.test(sfcast_rwnd1[,3],sfcast_ETS1[,3],power=2, alternative='g')
dm.test(sfcast_rwnd1[,3],sfcast_AR1[,3],power=2, alternative='g')
dm.test(sfcast_rwnd1[,3],sfcast_ARIMA_auto1[,3],power=2, alternative='g')


# Plot
plot(dfCPI_test, 
     type ='l', 
     main="CPI Inflation Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_rwnd1[,2],col="red",type="l", lty=2)
lines(sfcast_ETS1[,2],col="blue",type='l', lty=4)
lines(sfcast_AR1[,2],col="purple",type="l", lty=5)
lines(sfcast_ARIMA_auto1[,2],col="green",type="l", lty=4)
legend("topleft", legend = c("Data", "RWnd", "ets", "ARIMA(9,0,0)", "ARIMA(2,0,2)"),
       col = c("black","red", "blue",'purple',"green"), lty = 1:5, cex = 0.8)

# Transform list to matrix
sfcast_rwnd1 = list.rbind(sfcast_rwnd1)
sfcast_ETS1 = list.rbind(sfcast_ETS1)
sfcast_AR1 = list.rbind(sfcast_AR1)
sfcast_ARIMA_auto1 = list.rbind(sfcast_ARIMA_auto1)

# Collect the results for print out
results <- ts(cbind(dfCPI_test,sfcast_rwnd1[2,],sfcast_ETS1[2,],sfcast_AR1[2,],sfcast_ARIMA_auto1[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","RWnd","ETS","ARIMA(9,0,0)","ARIMA(2,0,2)")

print(results)

```

We will use RW with no drift to be the benchmark. As the result ARIMA(9,0,0) is perform the best for one step ahead forecast and the line also conform with the original data. We will use DM test to compare. From DM test, it did not confirm that ARIMA(9,0,0) perform the better than RW statistically significant (This suggests that two models statistically equivalent accuracy) (for one step ahead forecast). However, ARIMA(9,0,0) has improved prediction performance by 9.6% (economic significant)

From the plotting, it also confirm that ARIMA(9,0,0) with one step ahead forecast has the plotting line close to the testing set (raw data)

#GDP Growth Rate
```{r}
# Define useful inputs
T <- nrow(dfGDP_new)  # Number of time periods in data set
T0 <- nrow(dfGDP_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd2 = list()
sfcast_ETS2 = list()
sfcast_AR2 = list() #We will use this to store three series, which are actual, forecast, error
sfcast_ARIMA_auto2 = list()


# Loop
for (tt in 1:nfcasts) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train2 = ts(dfGDP_new[1:(T0+tt-1),]) 

  # Fit the models
  fit_ETS2 <- ets(y_train2) # Automatic selection of ets - may change over test sample
  fit_AR2.1 <- Arima(y_train2,c(6,0,0))
  fit_ARIMA_auto2 <- auto.arima(y_train2, seasonal=FALSE) # Automatic selection of ARIMA 
  
  
  
# One-step-ahead forecast 
  fcast_rwnd2 <- rwf(y_train2,h=1)
  fcast_ETS2 <- forecast::forecast(fit_ETS2,h=1)
  fcast_AR2.1 <- forecast::forecast(fit_AR2.1,h=1)
  fcast_ARIMA_auto2 <- forecast::forecast(fit_ARIMA_auto2,h=1)
  
  

# Collect objects of interest 
  yobs2 <- (dfGDP_new[T0+tt]) # Value we want to forecast
  
  yhat_rwnd2 <- fcast_rwnd2$mean[1]
  yhat_ETS2 <- fcast_ETS2$mean[1] 
  yhat_AR2.1 <- fcast_AR2.1$mean[1] # Point forecast
  yhat_ARIMA_auto2 <- fcast_ARIMA_auto2$mean[1]


  err_rwnd2 <- yhat_rwnd2 - yobs2
  err_ETS2 <- yhat_ETS2 - yobs2
  err_AR2.1 <- yhat_AR2.1 - yobs2 # Forecast error
  err_ARIMA_auto2 <- yhat_ARIMA_auto2 - yobs2
  
  
# Store point forecast
  sfcast_rwnd2[[tt]] = c(yobs2,yhat_rwnd2,err_rwnd2)
  sfcast_ETS2[[tt]] = c(yobs2,yhat_ETS2,err_ETS2)
  sfcast_AR2[[tt]] = c(yobs2,yhat_AR2.1,err_AR2.1)
  sfcast_ARIMA_auto2[[tt]] = c(yobs2,yhat_ARIMA_auto2,err_ARIMA_auto2)
  
}

# Transform list to matrix
sfcast_rwnd2 = ts(list.rbind(sfcast_rwnd2),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ETS2 = ts(list.rbind(sfcast_ETS2),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_AR2 = ts(list.rbind(sfcast_AR2),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ARIMA_auto2 = ts(list.rbind(sfcast_ARIMA_auto2),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_rwnd2 = sqrt(mean((sfcast_rwnd2[,3])^2))
RMSE_ETS2 <- sqrt(mean((sfcast_ETS2[,3])^2))
RMSE_AR2 <- sqrt(mean((sfcast_AR2[,3])^2))
RMSE_ARIMA_auto2 <- sqrt(mean((sfcast_ARIMA_auto2[,3])^2))

RMSE2 <- c(RMSE_rwnd2, 
            RMSE_ETS2,
          RMSE_AR2,
          RMSE_ARIMA_auto2)

#Present Results
RMSE2 #As the result RW with no drift is perform the best.

# DM Test with RWnd Benchmark - one tailed
dm.test(sfcast_rwnd2[,3],sfcast_ETS2[,3],power=2, alternative='g')
dm.test(sfcast_rwnd2[,3],sfcast_AR2[,3],power=2, alternative='g')
dm.test(sfcast_rwnd2[,3],sfcast_ARIMA_auto2[,3],power=2, alternative='g')


# Plot
plot(dfGDP_test, 
     type ='l', 
     main="GDP Growth Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_rwnd2[,2],col="red",type="l", lty=2)
lines(sfcast_ETS2[,2],col="blue",type='l', lty=4)
lines(sfcast_AR2[,2],col="purple",type="l", lty=5)
lines(sfcast_ARIMA_auto2[,2],col="green",type="l", lty=4)
legend("topleft", legend = c("Data", "RWnd", "ets", "ARIMA(6,0,0)", "ARIMA(3,0,2)"),
       col = c("black","red", "blue",'purple',"green"), lty = 1:5, cex = 0.8)

# Transform list to matrix
sfcast_rwnd2 = list.rbind(sfcast_rwnd2)
sfcast_ETS2 = list.rbind(sfcast_ETS2)
sfcast_AR2 = list.rbind(sfcast_AR2)
sfcast_ARIMA_auto2 = list.rbind(sfcast_ARIMA_auto2)

# Collect the results for print out
results <- ts(cbind(dfGDP_test,sfcast_rwnd2[2,],sfcast_ETS2[2,],sfcast_AR2[2,],sfcast_ARIMA_auto2[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","RWnd","ETS","ARIMA(6,0,0)","ARIMA(3,0,2)")

print(results)

```
We will use RW with no drift to be the benchmark. As the result ARIMA(6,0,0) is perform the best for one step ahead forecast and the line also conform with the original data. We will use DM test to compare. From DM test, it did not confirm that ARIMA(6,0,0) perform the better than RW statistically significant (for one step ahead forecast). However, ARIMA(6,0,0) is improve prediction performance (comparing from RMSE) by 0.9% (economic significant)

From the plotting, it also confirm that ARIMA(6,0,0) with one step ahead forecast has the plotting line close to the testing set (raw data)

#Unemployment Rate
```{r}
# Define useful inputs
T <- nrow(dfUM_new)  # Number of time periods in data set
T0 <- nrow(dfUM_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd3 = list()
sfcast_ETS3 = list()
sfcast_AR3 = list() #We will use this to store three series, which are actual, forecast, error
sfcast_ARIMA_auto3 = list()


# Loop
for (tt in 1:nfcasts) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train3 = ts(dfUM_new[1:(T0+tt-1),]) 

  # Fit the models
  fit_ETS3 <- ets(y_train3) # Automatic selection of ets - may change over test sample
  fit_AR3 <- Arima(y_train3,c(14,1,0))
  fit_ARIMA_auto3 <- auto.arima(y_train3, seasonal=FALSE) # Automatic selection of ARIMA 
  
  
  
# One-step-ahead forecast 
  fcast_rwnd3 <- rwf(y_train3,h=1)
  fcast_ETS3 <- forecast::forecast(fit_ETS3,h=1)
  fcast_AR3 <- forecast::forecast(fit_AR3,h=1)
  fcast_ARIMA_auto3 <- forecast::forecast(fit_ARIMA_auto3,h=1)
  
  

# Collect objects of interest 
  yobs3 <- (dfUM_new[T0+tt]) # Value we want to forecast
  
  yhat_rwnd3 <- fcast_rwnd3$mean[1]
  yhat_ETS3 <- fcast_ETS3$mean[1] 
  yhat_AR3 <- fcast_AR3$mean[1] # Point forecast
  yhat_ARIMA_auto3 <- fcast_ARIMA_auto3$mean[1]


  err_rwnd3 <- yhat_rwnd3 - yobs3
  err_ETS3 <- yhat_ETS3 - yobs3
  err_AR3 <- yhat_AR3 - yobs3 # Forecast error
  err_ARIMA_auto3 <- yhat_ARIMA_auto3 - yobs3
  
  
# Store point forecast
  sfcast_rwnd3[[tt]] = c(yobs3,yhat_rwnd3,err_rwnd3)
  sfcast_ETS3[[tt]] = c(yobs3,yhat_ETS3,err_ETS3)
  sfcast_AR3[[tt]] = c(yobs3,yhat_AR3,err_AR3)
  sfcast_ARIMA_auto3[[tt]] = c(yobs3,yhat_ARIMA_auto3,err_ARIMA_auto3)
  
}

# Transform list to matrix
sfcast_rwnd3 = ts(list.rbind(sfcast_rwnd3),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ETS3 = ts(list.rbind(sfcast_ETS3),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_AR3 = ts(list.rbind(sfcast_AR3),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
sfcast_ARIMA_auto3 = ts(list.rbind(sfcast_ARIMA_auto3),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_rwnd3 = sqrt(mean((sfcast_rwnd3[,3])^2))
RMSE_ETS3 <- sqrt(mean((sfcast_ETS3[,3])^2))
RMSE_AR3 <- sqrt(mean((sfcast_AR3[,3])^2))
RMSE_ARIMA_auto3 <- sqrt(mean((sfcast_ARIMA_auto3[,3])^2))

RMSE3 <- c(RMSE_rwnd3, 
            RMSE_ETS3,
          RMSE_AR3,
          RMSE_ARIMA_auto3)

#Present Results
RMSE3 #As the result RW with no drift is perform the best.

# DM Test with RWnd Benchmark - one tailed
dm.test(sfcast_rwnd3[,3],sfcast_ETS3[,3],power=2, alternative='g')
dm.test(sfcast_rwnd3[,3],sfcast_AR3[,3],power=2, alternative='g')
dm.test(sfcast_rwnd3[,3],sfcast_ARIMA_auto3[,3],power=2, alternative='g')


# Plot
plot(dfUM_test, 
     type ='l', 
     main="Unemployment Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_rwnd3[,2],col="red",type="l", lty=2)
lines(sfcast_ETS3[,2],col="blue",type='l', lty=4)
lines(sfcast_AR3[,2],col="purple",type="l", lty=5)
lines(sfcast_ARIMA_auto3[,2],col="green",type="l", lty=4)
legend("bottomleft", legend = c("Data", "RWnd", "ets", "ARIMA(14,1,0)", "ARIMA(0,1,1)"),
       col = c("black","red", "blue",'purple',"green"), lty = 1:5, cex = 0.8)

# Transform list to matrix
sfcast_rwnd3 = list.rbind(sfcast_rwnd3)
sfcast_ETS3 = list.rbind(sfcast_ETS3)
sfcast_AR3 = list.rbind(sfcast_AR3)
sfcast_ARIMA_auto3 = list.rbind(sfcast_ARIMA_auto3)

# Collect the results for print out
results <- ts(cbind(dfUM_test,sfcast_rwnd3[2,],sfcast_ETS3[2,],sfcast_AR3[2,],sfcast_ARIMA_auto3[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","RWnd","ETS","ARIMA(14,1,0)","ARIMA(0,1,1)")

print(results)

```

We will use RW with no drift to be the benchmark. As the result ARIMA(14,1,0) is perform the best for one step ahead forecast and the line also conform with the original data. We will use DM test to compare. From DM test, it confirm that ARIMA(14,1,0) perform the better than RW statistically significant (for one step ahead forecast). It is improve prediction performance (comparing from RMSE) by 24.8% (economic significant)

From the plotting, it also confirm that ARIMA(14,1,0) with one step ahead forecast has the plotting line close to the testing set (raw data)

#Summary of the Testing Set with one step ahead forecast

CPI Inflation, ARIMA(9,0,0) or AR(9) perform the best.
GDP Growth, ARIMA(6,0,0) or AR(6) perform the best.
UM Rate, ARIMA(14,1,0) AR(14) with first differenced perform the best.

##Multivariate Models

#Check multicolinearity
```{r}
combined_data |>
  GGally::ggpairs(columns = 2:5)
```
According to the correlation matrix, there is no multicolinearity issue. We can see that CPI inflation has the positive correlation to GDP growth. This suggests that increase GDP Growth has the potential to increase the inflation rate. However, CPI inflation has the negative correlation to unemployment rate. This make sense because if GDP growth increase, it suggests the increase of economic performance (positive impact to inflation rate). Therefore, the decreasing of unemployment rate (negative correlation). Cash Rate has the positive correlation on CPI Inflation (small positive correlation), GDP Growth Rate (small positive correlation), and Unemployment Rate (lager positive correlation). This imply that by increasing the cash rate, if the cash rate is not too high, it still have the potential to drive the good range of GDP Growth as people still able to spend money, business still running with the good amount of the interest rate. This lead to the good range for the inflation rate. However, the larger positive correlation between Cash Rate and Unemployment Rate suggests that there is the potential of higher cash rate will increase unemployment rate due to many business want to reduce their cost.

#Test Granger causality
Number of lag is 4 because it is a quaterly data
```{r}
# Specify the number of lags for y
nlags_y = 4

# Specify the number of lags for x
nlags_x = 4

# Test Granger causality of different variables using grangertest()
#Test GC of cash rate on Inflation, GDP Growth, and Unemployment rate
grangertest(x=combined_data[,5], y=combined_data[,2], order = nlags_x, test="F") 
grangertest(x=combined_data[,5], y=combined_data[,3], order = nlags_x, test="F") 
grangertest(x=combined_data[,5], y=combined_data[,4], order = nlags_x, test="F") 

#Test GC of Inflation on GDP Growth, Unemployment rate and Cash Rate
grangertest(x=combined_data[,2], y=combined_data[,3], order = nlags_x, test="F") 
grangertest(x=combined_data[,2], y=combined_data[,4], order = nlags_x, test="F") 
grangertest(x=combined_data[,2], y=combined_data[,5], order = nlags_x, test="F") 

#Test GC of GDP Growth on Inflation, Unemployment rate and Cash Rate
grangertest(x=combined_data[,3], y=combined_data[,2], order = nlags_x, test="F") 
grangertest(x=combined_data[,3], y=combined_data[,4], order = nlags_x, test="F") 
grangertest(x=combined_data[,3], y=combined_data[,5], order = nlags_x, test="F") 

#Test GC of Unemployment rate on Inflation, GDP Growth and Cash Rate
grangertest(x=combined_data[,4], y=combined_data[,2], order = nlags_x, test="F") 
grangertest(x=combined_data[,4], y=combined_data[,3], order = nlags_x, test="F") 
grangertest(x=combined_data[,4], y=combined_data[,5], order = nlags_x, test="F") 
```
The Granger causality test uses an F-test to determine whether the joint dynamics of a particular variable are important when predicting another variable. Since F-test and t-test are equivalent when we only have one parameter. 

x = cash rate
As the results, Inflation GC cash rate, Unemployment rate GC cash rate. GDP Growth GC cash rate at 10% significant level but GDP Growth will not GC cash rate at 5% significant level. This suggest that cash rate is useful in forecasting inflation, GDP Growth (10% significant level), and Unemployment rate

x = inflation
As the results, GDP Growth will not GC Inflation. This suggests that it is not useful to use inflation in forecasting GDP Growth. It is useful to use inflation for forecasting unemployment rate. However, it is not useful to use inflation to forecast cash rate (at 5% significant level) but it will be useful to forecast cash rate (at 10% significant level).

x = GDP Growth
As the results, Inflation will not GC GDP Growth. This suggests that it is not useful to use GDP Growth in forecasting Inflation. In addition, Cash rate will not GC GDP Growth. This suggests that it is not useful to use GDP Growth in forecasting Inflation. However, unemployment rate GC GDP Growth. This suggest that it is useful to use GDP Growth in forecasting unemployment rate.

x = unemployment rate
As the results, Inflation, GDP Growth, Cash rate will not GC GDP Growth. This suggest that it is not useful to use unemployment rate to forecast inflation, GDP Growth, or Cash rate.

#Summary results from Granger Causality
Forecasting inflation, it is useful to use cash rate for forecasting inflation. 
Forecasting GDP Growth, it is useful to use cash rate for forecasting GDP Growth (10% significant level)
Forecasting Unemployment rate, it is useful to use inflation, GDP Growth, cash rate

#Using VAR model

```{r}
# Redefine inflation as .ts object to use various forecasting packages
#Forecast Inflation

combined_data1 <- combined_data[,-c(3:4)]

dfcombined_data_infCR = ts(combined_data1[,-c(1)],
            start=c(1992, 1), 
            end=c(2023, 1), 
            frequency=4)

# Split into training and test sets1
ytrain1 = window(dfcombined_data_infCR,end=c(2011,4)) 
ytest1 = window(dfcombined_data_infCR,start=c(2012,1)) 

#Forecast GDP Growth
combined_data2 <- combined_data[,-c(2)]
combined_data2 <- combined_data2[,-c(3)]

dfcombined_data_GDPCR = ts(combined_data2[,-c(1)],
            start=c(1992, 1), 
            end=c(2023, 1), 
            frequency=4)

# Split into training and test sets2
ytrain2 = window(dfcombined_data_GDPCR,end=c(2011,4)) 
ytest2 = window(dfcombined_data_GDPCR,start=c(2012,1)) 

#Forecast Unemployment rate
dfcombined_data_UMinfGDPCR = ts(combined_data[,-c(1)],
            start=c(1992, 1), 
            end=c(2023, 1), 
            frequency=4)

# Split into training and test sets2
ytrain3 = window(dfcombined_data_UMinfGDPCR,end=c(2011,4)) 
ytest3 = window(dfcombined_data_UMinfGDPCR,start=c(2012,1)) 
```

```{r}
# Remove other variables for easier syntax (because after GC test, we knew that Inflation GC cash rate, GDP Growth GC cash rate, Unemployment GC Inflation, GDP Growth, and Cash rate)

#Inflation vs cash rate
#Use data from Inflation to cash rate only

# lag length
#CPI Inflation
VARselect(ytrain1, lag.max = 15,
          type = "const")
#GDP Growth
VARselect(ytrain2, lag.max = 15,
          type = "const")
#Unemployment Rate
VARselect(ytrain3, lag.max = 13,
          type = "const")
```
#In summary
We can select the lag length of the VAR model using information criteria. For forecasting inflation using cash rate as a predictor, the majority results above suggest that the VAR(2) is the best model according to all the selection criteria. For GDP Growth using cash rate as a predictor, the majority results above suggest that the VAR(5) is the best model according to the AIC and FPE. For Unemployment rate using all predictors, the results below suggest that the VAR(13) is the best model according to the AIC,HQ and FBE

```{r}
# estimation
var_CPICR1 <- VAR(ytrain1, 
                 p = 2, 
                 type = "const")

var_GDPCR1 <- VAR(ytrain2, 
                 p = 5, 
                 type = "const")


var_UMinfGDPCR1 <- VAR(ytrain3, 
                 p = 13, 
                 type = "const")
```

The results from the Portmanteau test for serial correlation show that for inflation, the VAR(2) model has no serial correlation. For GDP Growth, the VAR(5) has no serial correlation. For Unemployment rate, the VAR(13) models have serial correlation. 

#VAR with four step ahead forecast
#CPI
```{r}
# Define useful inputs
T <- nrow(dfcombined_data_infCR)  # Number of time periods in data set
T0 <- nrow(ytrain1)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd1.4M = list()
sfcast_CPICR1.4M = list()

# Loop
for (tt in 1:(nfcasts-4)) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train1.4M = ts(dfcombined_data_infCR[1:(T0+tt-1),]) 

  # Fit the models
  var_CPICR1.4M <- VAR(y_train1.4M, 
                 p = 2, 
                 type = "const")


# One-step-ahead forecast 
  fcast_CPICR1.4M <- forecast::forecast(var_CPICR1.4M,h=4)

  
  
# Collect objects of interest 
  yobsv <- (dfcombined_data_infCR[T0+tt]) # Value we want to forecast
  
  yhat_CPICR1.4M <- fcast_CPICR1.4M$forecast$CPI_Inflation$mean[1] 


  err_CPICR1.4M <- yhat_CPICR1.4M - yobsv

  
  
# Store point forecast
  sfcast_CPICR1.4M[[tt]] = c(yobsv,yhat_CPICR1.4M,err_CPICR1.4M)

}

sfcast_CPICR1.4M = ts(list.rbind(sfcast_CPICR1.4M),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_CPICR1.4M <- sqrt(mean((sfcast_CPICR1.4M[,3])^2))


RMSE5 <- c(RMSE_CPICR1.4M)


#Present Results
RMSE5 #As the result RW with no drift is perform the best.

# Plot
plot(dfCPI_test, 
     type ='l', 
     main="CPI Inflation Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_CPICR1.4M[,2],col="blue",type='l', lty=4)
legend("topleft", legend = c("Data", "VAR(2)"),
       col = c("black", "blue"), lty = 1:4, cex = 0.8)

# Transform list to matrix
sfcast_CPICR1.4M = list.rbind(sfcast_CPICR1.4M)

# Collect the results for print out
results <- ts(cbind(dfGDP_test,sfcast_CPICR1.4M[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","VAR(2)")

print(results)
```
#GDP Growth
```{r}
# Define useful inputs
T <- nrow(dfcombined_data_GDPCR)  # Number of time periods in data set
T0 <- nrow(dfGDP_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_GDPCR2.4M = list()

# Loop
for (tt in 1:(nfcasts-4)) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train2.4M = ts(dfcombined_data_GDPCR[1:(T0+tt-1),]) 

  # Fit the models
  var_GDPCR2.4M <- VAR(y_train2.4M, 
                 p = 5, 
                 type = "const")


# Four-step-ahead forecast 
  fcast_GDPCR2.4M <- forecast::forecast(var_GDPCR2.4M,h=4)

  
  
# Collect objects of interest 
  yobsv2.4M <- (dfcombined_data_GDPCR[T0+tt]) # Value we want to forecast
  yhat_GDPCR2.4M <- fcast_GDPCR2.4M$forecast$GDP_Growth_Rate$mean[1] 


  err_GDPCR2.4M <- yhat_GDPCR2.4M - yobsv2.4M

  
# Store point forecast
  sfcast_GDPCR2.4M[[tt]] = c(yobsv2.4M,yhat_GDPCR2.4M,err_GDPCR2.4M)

}

# Transform list to matrix
sfcast_GDPCR2.4M = ts(list.rbind(sfcast_GDPCR2.4M),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_var_GDPCR2.4M <- sqrt(mean((sfcast_GDPCR2.4M[,3])^2))


RMSE6 <- c(RMSE_var_GDPCR2.4M) #This is the best for UM model


#Present Results
RMSE6 #As the result RW with no drift is perform the best.

# Plot
plot(dfGDP_test, 
     type ='l', 
     main="GDP Growth Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_GDPCR2.4M[,2],col="blue",type='l', lty=4)
legend("bottomleft", legend = c("Data", "VAR(5)"),
       col = c("black", "blue"), lty = 1:4, cex = 0.8)

# Transform list to matrix
sfcast_GDPCR2.4M = list.rbind(sfcast_GDPCR2.4M)

# Collect the results for print out
results <- ts(cbind(dfGDP_test,sfcast_GDPCR2.4M[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","VAR(5)")

print(results)
```
#UM Rate
```{r}
# Define useful inputs
T <- nrow(dfcombined_data_UMinfGDPCR)  # Number of time periods in data set
T0 <- nrow(dfUM_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_UMinfGDPCR3.4M = list()

# Loop
for (tt in 1:(nfcasts-4)) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train3.4M = ts(dfcombined_data_UMinfGDPCR[1:(T0+tt-1),]) 

  # Fit the models
  var_UMinfGDPCR3.4M <- VAR(y_train3.4M, 
                 p = 13, 
                 type = "const")


# Four-step-ahead forecast 
  fcast_UMinfGDPCR3.4M <- forecast::forecast(var_UMinfGDPCR3.4M,h=4)

  
  
# Collect objects of interest 
  yobsv3.4M <- (dfUM_new[T0+tt]) # Value we want to forecast
  
  yhat_UMinfGDPCR3.4M <- fcast_UMinfGDPCR3.4M$forecast$Average_Unemployment_Rate$mean[1] 

  err_UMinfGDPCR3.4M <- yhat_UMinfGDPCR3.4M - yobsv3.4M

  
  
# Store point forecast
  sfcast_UMinfGDPCR3.4M[[tt]] = c(yobsv3.4M,yhat_UMinfGDPCR3.4M,err_UMinfGDPCR3.4M)

}

# Transform list to matrix
sfcast_UMinfGDPCR3.4M = ts(list.rbind(sfcast_UMinfGDPCR3.4M),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_var_UMinfGDPCR3.4M <- sqrt(mean((sfcast_UMinfGDPCR3.4M[,3])^2))


RMSE7 <- c(RMSE_var_UMinfGDPCR3.4M) #This is the best for UM model


#Present Results
RMSE7

# Plot
plot(dfUM_test, 
     type ='l', 
     main="Unemployment Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_UMinfGDPCR3.4M[,2],col="blue",type='l', lty=4)
legend("bottomleft", legend = c("Data", "VAR(13)"),
       col = c("black", "blue"), lty = 1:4, cex = 0.8)

# Transform list to matrix
sfcast_UMinfGDPCR3.4M = list.rbind(sfcast_UMinfGDPCR3.4M)

# Collect the results for print out
results <- ts(cbind(dfUM_test,sfcast_UMinfGDPCR3.4M[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","VAR(13)")

print(results)
```
```{r}
# Portmanteau test for serial correlation
serial.test(var_CPICR1.4M, lags.pt=15, type="PT.asymptotic")
serial.test(var_GDPCR2.4M, lags.pt=15, type="PT.asymptotic")
serial.test(var_UMinfGDPCR3.4M, lags.pt=15, type="PT.asymptotic")
```


```{r}
# Check eigenvalues
check1.4 <- max(abs(roots(var_CPICR1.4M)))
show(check1.4) #0.9757324
check2.4 <- max(abs(roots(var_GDPCR2.4M)))
show(check2.4) #0.9805782
check3.4 <- max(abs(roots(var_UMinfGDPCR3.4M)))
show(check3.4) #1.015369
```

#VAR with one step ahead forecast

#CPI
```{r}
# Define useful inputs
T <- nrow(dfcombined_data_infCR)  # Number of time periods in data set
T0 <- nrow(ytrain1)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_rwnd1.1 = list()
sfcast_CPICR1 = list()

# Loop
for (tt in 1:nfcasts) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train1 = ts(dfcombined_data_infCR[1:(T0+tt-1),]) 

  # Fit the models
  var_CPICR1 <- VAR(y_train1, 
                 p = 2, 
                 type = "const")
  

# One-step-ahead forecast 
  fcast_CPICR1 <- forecast::forecast(var_CPICR1,h=1)

  
  
# Collect objects of interest 
  yobsv <- (dfcombined_data_infCR[T0+tt]) # Value we want to forecast
  
  yhat_CPICR1 <- fcast_CPICR1$forecast$CPI_Inflation$mean[1] 


  err_CPICR1 <- yhat_CPICR1 - yobsv

  
  
# Store point forecast
  sfcast_CPICR1[[tt]] = c(yobsv,yhat_CPICR1,err_CPICR1)

}

sfcast_CPICR1 = ts(list.rbind(sfcast_CPICR1),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```


```{r}
# Compute RMSE (compute manually here)
#RMSE_rwnd1.1 = sqrt(mean((sfcast_rwnd1.1[,3])^2))
RMSE_CPICR1 <- sqrt(mean((sfcast_CPICR1[,3])^2))


RMSE5 <- c(RMSE_CPICR1)


#Present Results
RMSE5 #As the result RW with no drift is perform the best.

# Plot
plot(dfCPI_test, 
     type ='l', 
     main="CPI Inflation Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_CPICR1[,2],col="blue",type='l', lty=4)
legend("topleft", legend = c("Data", "VAR(2)"),
       col = c("black", "blue"), lty = 1:4, cex = 0.8)

# Transform list to matrix
sfcast_CPICR1 = list.rbind(sfcast_CPICR1)

# Collect the results for print out
results <- ts(cbind(dfGDP_test,sfcast_CPICR1[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","VAR(2)")

print(results)
```
#GDP Growth
```{r}
# Define useful inputs
T <- nrow(dfcombined_data_GDPCR)  # Number of time periods in data set
T0 <- nrow(dfGDP_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_GDPCR1 = list()

# Loop
for (tt in 1:nfcasts) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train2 = ts(dfcombined_data_GDPCR[1:(T0+tt-1),]) 

  # Fit the models
  var_GDPCR1 <- VAR(y_train2, 
                 p = 5, 
                 type = "const")


# One-step-ahead forecast 
  fcast_GDPCR1 <- forecast::forecast(var_GDPCR1,h=1)

  
  
# Collect objects of interest 
  yobsv <- (dfcombined_data_GDPCR[T0+tt]) # Value we want to forecast
  yhat_GDPCR1 <- fcast_GDPCR1$forecast$GDP_Growth_Rate$mean[1] 


  err_GDPCR1 <- yhat_GDPCR1 - yobsv

  
# Store point forecast
  sfcast_GDPCR1[[tt]] = c(yobsv,yhat_GDPCR1,err_GDPCR1)

}

# Transform list to matrix
sfcast_GDPCR1 = ts(list.rbind(sfcast_GDPCR1),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_var_GDPCR1 <- sqrt(mean((sfcast_GDPCR1[,3])^2))


RMSE6 <- c(RMSE_var_GDPCR1) #This is the best for UM model


#Present Results
RMSE6 #As the result RW with no drift is perform the best.

# Plot
plot(dfGDP_test, 
     type ='l', 
     main="GDP Growth Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_GDPCR1[,2],col="blue",type='l', lty=4)
legend("bottomleft", legend = c("Data", "VAR(5)"),
       col = c("black", "blue"), lty = 1:4, cex = 0.8)

# Transform list to matrix
sfcast_GDPCR1 = list.rbind(sfcast_GDPCR1)

# Collect the results for print out
results <- ts(cbind(dfGDP_test,sfcast_GDPCR1[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","VAR(5)")

print(results)
```

#UM Rate
```{r}
# Define useful inputs
T <- nrow(dfcombined_data_UMinfGDPCR)  # Number of time periods in data set
T0 <- nrow(dfUM_train)     # Start of the test period
nfcasts <- T-T0        # number of forecast periods

# Storage
sfcast_UMinfGDPCR1 = list()

# Loop
for (tt in 1:nfcasts) { 
# Update progress bar   
  progress(100*tt/nfcasts)
  
# Update training set
  y_train3 = ts(dfcombined_data_UMinfGDPCR[1:(T0+tt-1),]) 

  # Fit the models
  var_UMinfGDPCR1 <- VAR(y_train3, 
                 p = 13, 
                 type = "const")


# One-step-ahead forecast 
  fcast_UMinfGDPCR1 <- forecast::forecast(var_UMinfGDPCR1,h=1)

  
  
# Collect objects of interest 
  yobsv <- (dfUM_new[T0+tt]) # Value we want to forecast
  
  yhat_UMinfGDPCR1 <- fcast_UMinfGDPCR1$forecast$Average_Unemployment_Rate$mean[1] 

  err_UMinfGDPCR1 <- yhat_UMinfGDPCR1 - yobsv

  
  
# Store point forecast
  sfcast_UMinfGDPCR1[[tt]] = c(yobsv,yhat_UMinfGDPCR1,err_UMinfGDPCR1)

}

# Transform list to matrix
sfcast_UMinfGDPCR1 = ts(list.rbind(sfcast_UMinfGDPCR1),
               start=c(2012, 1), 
               end=c(2023, 1), 
               frequency=4)
```

```{r}
# Compute RMSE (compute manually here)
RMSE_var_UMinfGDPCR1 <- sqrt(mean((sfcast_UMinfGDPCR1[,3])^2))


RMSE7 <- c(RMSE_var_UMinfGDPCR1) #This is the best for UM model


#Present Results
RMSE7

# Plot
plot(dfUM_test, 
     type ='l', 
     main="Unemployment Rate Forecasts",
     ylab = 'Percent %',
     xlab = 'Dates')
lines(sfcast_UMinfGDPCR1[,2],col="blue",type='l', lty=4)
legend("bottomleft", legend = c("Data", "VAR(13)"),
       col = c("black","red", "blue"), lty = 1:4, cex = 0.8)

# Transform list to matrix
sfcast_UMinfGDPCR1 = list.rbind(sfcast_UMinfGDPCR1)

# Collect the results for print out
results <- ts(cbind(dfUM_test,sfcast_UMinfGDPCR1[2,]), start = c(2012,1), frequency = 4)

colnames(results) <- c("Data","VAR(13)")

print(results)
```
```{r}
# Portmanteau test for serial correlation
serial.test(var_CPICR1, lags.pt=15, type="PT.asymptotic")
serial.test(var_GDPCR1, lags.pt=15, type="PT.asymptotic")
serial.test(var_UMinfGDPCR1, lags.pt=15, type="PT.asymptotic")
```
```{r}
# Check eigenvalues
check1 <- max(abs(roots(var_CPICR1)))
show(check1) #0.9438806
check2 <- max(abs(roots(var_GDPCR1)))
show(check2) #0.9381574
check3 <- max(abs(roots(var_UMinfGDPCR1)))
show(check3) #0.9966903
```
#DM Test
#Now compare univariate and multivariate for four step ahead forecast
```{r}
#Forecast Inflation
dm.test(sfcast_AR1.4[,3],sfcast_CPICR1.4M[,3],power=2, alternative='g') #ARIMA(9,0,0) is the best
#Forecast GDP Growth
dm.test(sfcast_AR2.4[,3],sfcast_GDPCR2.4M[,3],power=2, alternative='g') #ARIMA(6,0,0) is the best
#Forecast Unemployment Rate
dm.test(sfcast_AR3.4[,3],sfcast_UMinfGDPCR3.4M[,3],power=2, alternative='g') #ARIMA(14,1,0) is the best
```

According to the results, for four step ahead forecast AR(9) perform the best to forecast inflation compare to VAR(2) and AR(6) is perform the best for GDP Growth compare to VAR(5). In addition, ARIMA(14,1,0) is perform the best for unemployment rate.

#Now compare univariate and multivariate for one step ahead forecast
```{r}
#Forecast Inflation
dm.test(sfcast_CPICR1[,3],sfcast_AR1[,3],power=2, alternative='g') #ARIMA(9,0,0) is the best
#Forecast GDP Growth
dm.test(sfcast_GDPCR1[,3],sfcast_AR2[,3],power=2, alternative='g') #ARIMA(6,0,0) is the best
#Forecast Unemployment Rate
dm.test(sfcast_UMinfGDPCR1[,3],sfcast_AR3[,3],power=2, alternative='g') #ARIMA(14,1,0) is the best
```
According to the results, for four step ahead forecast AR(9) perform the best to forecast inflation compare to VAR(2) and AR(6) is perform the best for GDP Growth compare to VAR(5). In addition, ARIMA(14,1,0) is perform the best for unemployment rate. Eventhough the DM test are not statistically significant but AR models have improved the prediction performance by 15.1%, 7.5% (statistically significant at 10% level), and 16.6% (economic significant).

#Use the best model to forecast Inflation, GDP Growth, Unemployment Rate of Four step ahead forecast

```{r}
#Inflation 
fit_AR1.4 <- Arima(dfCPI_new,c(9,0,0))

# four-step-ahead forecast 
  fcast_AR1.4_fourstepahead <- forecast::forecast(fit_AR1.4,h=4)
  fcast_AR1.4_fourstepahead

#GDP Growth 
fit_AR2.4 <- Arima(dfGDP_new,c(6,0,0))


# four-step-ahead forecast 
  fcast_AR2.4_fourstepahead <- forecast::forecast(fit_AR2.4,h=4)
  fcast_AR2.4_fourstepahead


#Unemployment Rate 
  #Fit model
fit_AR3.4 <- Arima(dfUM_new,c(14,1,0))


# four-step-ahead forecast 
  fcast_AR3.4_fourstepahead <- forecast::forecast(fit_AR3.4,h=4)
  fcast_AR3.4_fourstepahead
```

#Use the best model to forecast Inflation, GDP Growth, Unemployment Rate of one step ahead forecast

```{r}
#Inflation 
fit_AR1 <- Arima(dfCPI_new,c(9,0,0))

# One-step-ahead forecast 
  fcast_AR1_onestepahead <- forecast::forecast(fit_AR1,h=1)
  fcast_AR1_onestepahead

#GDP Growth 
fit_AR2 <- Arima(dfGDP_new,c(6,0,0))


# One-step-ahead forecast 
  fcast_AR2_onestepahead <- forecast::forecast(fit_AR2,h=1)
  fcast_AR2_onestepahead


#Unemployment Rate 
  #Fit model
fit_AR3 <- Arima(dfUM_new,c(14,1,0))


# One-step-ahead forecast 
  fcast_AR3_onestepahead <- forecast::forecast(fit_AR3,h=1)
  fcast_AR3_onestepahead
```

#Graph one-year-ahead forecast
```{r}
# Draw Graph
par(mfrow=c(1,1))
plot(fcast_AR1.4_fourstepahead,
     main="ARIMA(9,0,0) one-year-ahead forecasts of Inflation")
lines(dfCPI_test)

plot(fcast_AR2.4_fourstepahead,
     main="ARIMA(6,0,0) one-year-ahead forecasts of GDP Growth")
lines(dfGDP_test)

plot(fcast_AR3.4_fourstepahead,
     main="ARIMA(14,1,0) one-year-ahead forecasts of Unemployment Rate")
lines(dfUM_test)
```
#Graph one-step-ahead forecast
```{r}
# Draw Graph
par(mfrow=c(1,1))
plot(fcast_AR1_onestepahead,
     main="ARIMA(9,0,0) one-step-ahead forecasts of Inflation")
lines(dfCPI_test)

plot(fcast_AR2_onestepahead,
     main="ARIMA(6,0,0) one-step-ahead forecasts of GDP Growth")
lines(dfGDP_test)

plot(fcast_AR3_onestepahead,
     main="ARIMA(14,1,0) one-step-ahead forecasts of Unemployment Rate")
lines(dfUM_test)
```
#Residual of the best model

#Inflation ARIMA(9,0,0)
```{r}
# Residuals
# Plot
plot(fit_AR1.4$residuals, 
     type = 'l', 
     main = "ARIMA(9,0,0) residuals for inflation: 1992Q1-2023Q1",
     ylab = 'Residuals',
     xlab = 'Dates')

# Convert to tsibble object
err_constant1.4 <- as_tsibble(fit_AR1.4$residuals)

# Rename Columns
colnames(err_constant1.4) = c("Dates","Residuals")

# ACF
err_constant1.4 |>
  ACF(Residuals, lag_max = 40) |>
  autoplot() + 
  labs(title="Inflation ACF: Residuals")
  
# PACF
err_constant1.4 |>
  PACF(Residuals, lag_max = 40) |>
  autoplot() + 
  labs(title="Inflation PACF: Residuals")

Box.test(fit_AR1.4$residuals, lag = 15, type = "Ljung") #White noise

par(mfrow=c(1,1))
qqnorm(fit_AR1.4$residuals, main = "Q-Q Plot of Residuals: Inflation")
qqline(fit_AR1.4$residuals, col = "steelblue", lwd = 2)
#Histogram of residuals plot
ggplot(data = dfCPI_new, aes(x = fit_AR1.4$residuals)) +
    geom_histogram(binwidth =1, fill = 'steelblue', color = 'black') +
    labs(title = 'Histogram of Residuals: Inflation ARIMA(9,0,0)', x = 'Residuals', y = 'Frequency') #Bins into 20bars
```
#GDP Growth
```{r}
# Residuals
# Plot
plot(fit_AR2.4$residuals, 
     type = 'l', 
     main = "ARIMA(6,0,0) residuals for GDP Growth: 1992Q1-2023Q1",
     ylab = 'Residuals',
     xlab = 'Dates')

# Convert to tsibble object
err_constant2.4 <- as_tsibble(fit_AR2.4$residuals)

# Rename Columns
colnames(err_constant2.4) = c("Dates","Residuals")

# ACF
err_constant2.4 |>
  ACF(Residuals, lag_max = 40) |>
  autoplot() + 
  labs(title="GDP Growth ACF: Residuals")
  
# PACF
err_constant2.4 |>
  PACF(Residuals, lag_max = 40) |>
  autoplot() + 
  labs(title="GDP Growth PACF: Residuals")

Box.test(fit_AR2.4$residuals, lag = 15, type = "Ljung") #White noise

par(mfrow=c(1,1))
qqnorm(fit_AR2.4$residuals, main = "Q-Q Plot of Residuals: GDP Growth")
qqline(fit_AR2.4$residuals, col = "steelblue", lwd = 2)
#Histogram of residuals plot
ggplot(data = dfGDP_new, aes(x = fit_AR2.4$residuals)) +
    geom_histogram(binwidth =1, fill = 'steelblue', color = 'black') +
    labs(title = 'Histogram of Residuals: GDP Growth ARIMA(6,0,0)', x = 'Residuals', y = 'Frequency') #Bins into 20bars
```
#Unemployment Rate
```{r}
# Residuals
# Plot
plot(fit_AR3.4$residuals, 
     type = 'l', 
     main = "ARIMA(14,1,0) residuals for Unemployment Rate: 1992Q1-2023Q1",
     ylab = 'Residuals',
     xlab = 'Dates')

# Convert to tsibble object
err_constant3.4 <- as_tsibble(fit_AR3.4$residuals)

# Rename Columns
colnames(err_constant3.4) = c("Dates","Residuals")

# ACF
err_constant3.4 |>
  ACF(Residuals, lag_max = 40) |>
  autoplot() + 
  labs(title="Unemployment Rate ACF: Residuals")
  
# PACF
err_constant3.4 |>
  PACF(Residuals, lag_max = 40) |>
  autoplot() + 
  labs(title="Unemployment Rate PACF: Residuals")

Box.test(fit_AR3.4$residuals, lag = 15, type = "Ljung") #White noise

par(mfrow=c(1,1))
qqnorm(fit_AR3.4$residuals, main = "Q-Q Plot of Residuals: Unemployment Rate")
qqline(fit_AR3.4$residuals, col = "steelblue", lwd = 2)
#Histogram of residuals plot
ggplot(data = dfUM_new, aes(x = fit_AR3.4$residuals)) +
    geom_histogram(binwidth =0.2, fill = 'steelblue', color = 'black') +
    labs(title = 'Histogram of Residuals: Unemployment Rate ARIMA(14,1,0)', x = 'Residuals', y = 'Frequency') #Bins into 20bars
```
